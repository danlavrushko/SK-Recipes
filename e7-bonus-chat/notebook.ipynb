{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Reminder: This üìò `.NET Interactive` notebook needs to be run from VS Code with [these prerequisites](../PREREQS.md)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use this notebook: \n",
    "\n",
    "* Just read the text and scroll along until you run into code blocks.\n",
    "* Code blocks have computer code inside them ‚Äî hover over the block and you can run the code.\n",
    "* Run the code by hitting the ‚ñ∂Ô∏è \"play\" button to the left. If the code runs you'll see a ‚úîÔ∏è. If not, you'll get a ‚ùå.\n",
    "* The output and status of the code block will appear just below itself ‚Äî you need to scroll down further to see it.\n",
    "* Sometimes a code block will ask you for input in a hard-to-notice dialog box üëÜ at the top of your notebook window. \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Recipe: üí¨ MiniChatGPT Clone\n",
    "## üßë‚Äçüç≥ Cook a simple \"ChatGPT\" clone\n",
    "\n",
    "The magic of chat using LLM AI is that it's extremely simple to implement. If you're still feeling unsure about semantic functions, catch up [here](https://learn.microsoft.com/en-us/semantic-kernel/howto/semanticfunctions). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Let's get started by instantiating a üî• kernel\n",
    "\n",
    "You've already set up your API key information, so this should be an easy ‚ñ∂Ô∏è and you're good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 0.15.230531.5-preview\"\n",
    "\n",
    "#!import ../config/Settings.cs\n",
    "\n",
    "using Microsoft.SemanticKernel;\n",
    "using System.IO;\n",
    "using Microsoft.SemanticKernel.SemanticFunctions;\n",
    "\n",
    "// Grab the locally stored credentials from the settings.json file. Name the \"backend\" as \"davinci\" ‚Äî assuming that you're using one of the davinci completion models. \n",
    "\n",
    "var (useAzureOpenAI, model, azureEndpoint, apiKey, orgId) = Settings.LoadFromFile();\n",
    "\n",
    "IKernel kernel = Microsoft.SemanticKernel.Kernel.Builder\n",
    "    .WithAzureChatCompletionService(\n",
    "        deploymentName: model,\n",
    "        endpoint: azureEndpoint,\n",
    "        apiKey: apiKey\n",
    "    )\n",
    "    .Build();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üò± **Get an error message?** The [first notebook](../s1e1-ez-starter-notebook/notebook.ipynb) walks you through this process so you should be all set. But if you're still stuck, go to https://aka.ms/sk/discord where we have realtime support."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2Ô∏è: Use the `ChatSkill` üßÇ skill to build a chatting AI in no time\n",
    "\n",
    "We will be using the `Chat` and `ChatPersona` semantic functions that are accessible from within the `ChatSkill` subdirectory of `skills`\n",
    "\n",
    "```\n",
    "üóÇÔ∏è skills\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ üìÅ FunSkill\n",
    "‚îî‚îÄ‚îÄ‚îÄ üìÅ ChatSkill\n",
    "     |\n",
    "     ‚îî‚îÄ‚îÄ‚îÄ üìÇ Chat\n",
    "     ‚îî‚îÄ‚îÄ‚îÄ üìÇ ChatPersona\n",
    "```\n",
    "\n",
    "And with that, let's get the LLM AI to tell us talk to us."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Create a simple chat loop using a basic kind of ü•ë memory\n",
    "\n",
    "You'll be surprised to see how easy it is to make AI chat happen with the semantic function `ChatSkill.Chat.` It's easy as `history += <the new chat exchange>`! Or in other words, create a prompt that is incrementally just your running conversation that gets fed into the prompt each turn of the chat. The LLM's job then simply becomes the task to auto-complete what should get said next. The context is a kind of persistent ü•ë memory that gradually increases the richness of the prompt as more conversation is fed into `history.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Orchestration;\n",
    "using InteractiveKernel = Microsoft.DotNet.Interactive.Kernel;\n",
    "\n",
    "// Load the Skills Directory\n",
    "var skillsDirectory = Path.Combine(System.IO.Directory.GetCurrentDirectory(), \"skills\");\n",
    "\n",
    "// Load the Chat function from the FunSkill\n",
    "var skill = kernel.ImportSemanticSkillFromDirectory(skillsDirectory, \"ChatSkill\");\n",
    "\n",
    "var myContext = new ContextVariables(); \n",
    "var botPrompt = \"AI: Hello. What's your name?\";\n",
    "var history = $\"{botPrompt}\\n\";\n",
    "\n",
    "const int numberOfRounds = 4;\n",
    "\n",
    "myContext.Set(\"history\", history); \n",
    "\n",
    "for(var i = 0; i < numberOfRounds; i++) {\n",
    "    try {\n",
    "        // get input from the user and set the context variable\n",
    "        Console.WriteLine(\"üëÜ Enter text in the input cell above to chat with the bot. üëÜ\\n\");\n",
    "        var input = await InteractiveKernel.GetInputAsync($\"{botPrompt} ({(i+1)} of {numberOfRounds})\");\n",
    "        myContext.Set(\"input\", input); \n",
    "\n",
    "        // run the chat function\n",
    "        var myResult = await kernel.RunAsync(myContext,skill[\"Chat\"]);\n",
    "\n",
    "        // tack onto the history üëá what's come back from the model\n",
    "        /********************************************************/\n",
    "        var theNewChatExchange = $\"Me: {input}\\nAI:{myResult}\\n\";\n",
    "        history += theNewChatExchange;\n",
    "        myContext.Set(\"history\", history); \n",
    "        /********************************************************/\n",
    "        // this way the new chat exchange gets passed into the next round\n",
    "\n",
    "        // announce the number of rounds and the history\n",
    "        Console.WriteLine($\"Chat for {i+1} of {numberOfRounds} rounds with AI:\\n{history}\");\n",
    "\n",
    "        // prepare to \"prompt\" the user with the bot's response\n",
    "        botPrompt = $\"AI: {myResult}\";\n",
    "    } catch {\n",
    "        // if the user hits \"Escape\" we end the chat early\n",
    "        Console.WriteLine(\"AI: Thanks for the wonderful chat!\");\n",
    "        break;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚úÖ Note that the chat appears in the output above as you enter text in the little textbox that appears at the top of VS Code. It will stop after you've gone for `numberOfRounds` ‚Äî so increase the number of rounds you'd like to chat with YOUR bot! You made it yourself!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Create a chat loop using ü•ë memory and with a personality of your choice\n",
    "\n",
    "The accrual of `history += theNewChatExchange` is a beautiful thing to admire. This is the basic mechanism whereby the chats you have with ChatGPT can feel so realistic. That's because the prompt is getting slightly longer and longer as you chat. The reason \"it gets you\" is because it hasn't forgotten what it's chatted with you in the past. It's the extra ü•ë \"fat\" that makes the interaction with the AI so much more appealing.\n",
    "\n",
    "Yet another facet to consider is how you're able to change the personality of the bot so easily. We'll use the `ChatSkill.ChatPersonality` function to do so with its added `$personality` context variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Orchestration;\n",
    "using InteractiveKernel = Microsoft.DotNet.Interactive.Kernel;\n",
    "\n",
    "// Load the Skills Directory\n",
    "var skillsDirectory = Path.Combine(System.IO.Directory.GetCurrentDirectory(), \"skills\");\n",
    "\n",
    "// Load the Chat function from the FunSkill\n",
    "var skill = kernel.ImportSemanticSkillFromDirectory(skillsDirectory, \"ChatSkill\");\n",
    "\n",
    "var myContext = new ContextVariables(); \n",
    "var botName = \"AI\";\n",
    "\n",
    "// Choose a personality here üëá ...\n",
    "/*********************************************************************/\n",
    "var personality = \"grumpy and extremely unhelpful\";\n",
    "/*********************************************************************/\n",
    "\n",
    "var botPrompt = $\"AI: Hello. My responses will be {personality}.\";\n",
    "var history = $\"{botPrompt}\\n\";\n",
    "\n",
    "const int numberOfRounds = 4;\n",
    "\n",
    "myContext.Set(\"history\", history); \n",
    "myContext.Set(\"personality\", personality);\n",
    "\n",
    "for(var i = 0; i < numberOfRounds; i++) {\n",
    "    try {\n",
    "        // get input from the user and set the context variable\n",
    "        Console.WriteLine(\"üëÜ Enter text in the input cell above to chat with the bot. üëÜ\\n\");\n",
    "        var input = await InteractiveKernel.GetInputAsync(botPrompt);\n",
    "        myContext.Set(\"input\", input); \n",
    "\n",
    "        // run the chat function\n",
    "        var myResult = await kernel.RunAsync(myContext,skill[\"ChatPersonality\"]);\n",
    "\n",
    "        // tack onto the history what's come out\n",
    "        var theNewChatExchange = $\"Me: {input}\\nAI:{myResult}\\n\";\n",
    "        history += theNewChatExchange;\n",
    "        myContext.Set(\"history\", history); \n",
    "\n",
    "        // announce the number of rounds and the history\n",
    "        Console.WriteLine($\"Chat for {i+1} of {numberOfRounds} rounds with {botName}:\\n{history}\");\n",
    "\n",
    "        // prepare to \"prompt\" the user with the bot's response\n",
    "        botPrompt = $\"AI: {myResult}\";\n",
    "    } catch {\n",
    "        // if the user hits \"Escape\" we end the chat early\n",
    "        Console.WriteLine($\"AI: Thanks for the wonderful chat!\");\n",
    "        break;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚è≠Ô∏è Next Steps\n",
    "\n",
    "Run through more advanced examples in the notebooks that are available in our GitHub repo at [https://aka.ms/sk/repo](https://aka.ms/sk/repo).\n",
    "\n",
    "[Want to deepen your \"prompt engineer\" chops? Go deeper on semantic AI üßÇüî•! ](../e8-bonus-prompts/notebook.ipynb)\n",
    "\n",
    "Or stay a longer while and modify the `numberOfRounds` parameter for a longer chat. Even better, chang ethe `personality` parameter in Step 2.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
